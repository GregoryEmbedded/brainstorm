<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Brainstorm AI - Présentation</title>
    <style>
        html {
            scroll-behavior: smooth;
        }
 
        .timeline {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 20px;
            height: 250px;
            overflow-y: auto;
       
        }

        .timeline-item {
            margin-bottom: 20px;
            background-color: grey;
            padding: 10px;
            border-radius: 8px;
            width: 80%;
            text-align: center;
            transition: background-color 0.3s ease;
        }
        .timeline-item:hover {
            background-color: darkgrey; 
            cursor: pointer; 
            box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3);
        }

        .timeline-link {
            color: white;
            text-decoration: none;
        }

        .timeline-date {
            font-weight: bold;
            font-size: 1.2em;
        }

        .timeline-item p {
            margin: 10px 0;
        }

        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        .gallery {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            justify-content: center;
            margin-top: 20px;
            max-width: 800px;
        }

        .gallery video {
            height: auto;
            max-width: 100%;
        }

        body {
            font-family: Arial, sans-serif;
            padding: 0;
            background-color: black;
            color: white
        }

        header {
            background-color: dark;
            color: white;
            padding: 15px;
            text-align: center;
        }

        nav {
            position: relative;
            display: flex;
            flex-direction: row;
            align-items: center;
            justify-content: center; /* Centre les éléments horizontalement */
            background-color: dark;
            color: white;
            margin: 0 auto;
            gap: 20px; 
            padding: 10px 0; /* Ajoute un peu d'espace autour des liens */
        }

        nav a {
            color: white;
            text-decoration: none;
            text-align: center;
        }

        nav a:hover {
            background-color: darkgrey; 
            cursor: pointer; 
            box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3);
        }


        .section {
            text-align: center;
            margin-left: 2rem;
            margin-right: 2rem;
        }

        .gallery img {
            width: 100%;
        }

        footer {
            text-align: center;
            padding: 10px;
            background-color: black;
            color: white;
            margin-top: 20px;
        }

        #accueil.section {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        #date1 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        #date2 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        #date3 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        #date4 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        #date5 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #date6 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #date7 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #date8 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #date9 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #date10 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        #date100 {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .marquee-container {
            width: 100%;
            overflow: hidden;
            white-space: nowrap;
            position: relative;
        }

        .marquee-text {
            display: inline-block;
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            animation: marquee 1s linear 1 forwards;
        }
        @keyframes marquee {
            from { transform: translateY(-200%); }
            to { transform: translateY(000%); }
        }

        @media (min-width: 1200px) {
            .section {
                margin-left: 10rem;
                margin-right: 10rem;
            }

            .gallery img {
                max-width: 40vw;
            }

            .gallery video {
                max-width: 30vw;
            }

            nav {
                max-width: 20vw;
                margin: 0 auto;
            }

        }
        #backToTop {
           position: fixed;
           bottom: 20px;
           right: 20px;
           padding: 12px 16px;
           font-size: 16px;
           background-color: white;
           color: white;
           border: none;
           border-radius: 5px;
           cursor: pointer;
           display: none; /* Caché au départ */
           transition: opacity 0.3s ease-in-out;
       }

       #backToTop:hover {
           background-color: #0056b3;
       }
       #linkedinBtn {
          position: fixed;
          width: 40px;
          height: 40px;
          border: none;
          background-color: white;
          border-radius: 50%;
          display: flex;
          align-items: center;
          justify-content: center;
          cursor: pointer;
          transition: opacity 0.3s ease-in-out;
          z-index: 1000; 
          top: 90%; /* Décale le bouton vers le bas de 90% de la hauteur de la fenêtre */
          left: 2%;
       }

       #linkedinBtn img {
          width: 28px;
          height: 28px;
       }

       #linkedinBtn:hover {
          background-color: black;
       }

       #linkedinBtn:focus {
          outline: none; /* Supprime l'effet de focus pour ne pas gêner l'apparence */ 
       }
       #GitHubBtn {
          position: fixed;
          width: 40px;
          height: 40px;
          border: none;
          background-color: white;
          border-radius: 50%;
          display: flex;
          align-items: center;
          justify-content: center;
          cursor: pointer;
          transition: opacity 0.3s ease-in-out;
          z-index: 1000;
          top: 80%; /* Décale le bouton vers le bas de 80% de la hauteur de la fenêtre */
          left: 2%;
       }

       #GitHubBtn img {
          width: 28px;
          height: 28px;
       }

       #GitHubBtn:hover {
          background-color: grey;
       }

       #GitHubBtn:focus {
          outline: none; /* Supprime l'effet de focus pour ne pas gêner l'apparence */ 
       }



</style>
</head>

<body>

    <button id="backToTop" onclick="scrollToTop()">⬆️
    </button>
    <button id="linkedinBtn" onclick="openLinkedIn()">
       <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" alt="LinkedIn">
    </button>
    <button id="GitHubBtn" onclick="GitHub()">
       <img src="https://cdn-icons-png.flaticon.com/512/25/25231.png" alt="GitHub">
    </button>

    <header>

        <div class="marquee-container">
            <h1 class="marquee-text">Brainstorm AI, l'IA santé⚕️</h1>
        </div>
        
    </header>
    <nav>
        <a href="#accueil">Accueil</a>
        <a href="#brainstorm">Brainstorm</a>
        <!-- <a href="#NeuronDetect">NeuronDetect</a> -->
        <a href="#quisuisje">Fondateur</a>
        <a href="#contact">Contact</a>
    </nav>

    <section id="accueil" class="section">
        <h2>Accueil</h2>
        <p>Bienvenue sur la page de présentation de l'application Brainstorm
           
        </p>
    
        <div class="gallery">
            <figure>
                <img src="image/Brainstorm AI logo.png" alt="Développement en cours">
                <figcaption>"Fostering Innovation for Human Healthcare!"</figcaption>
            </figure>
        </div>
        <p>
            >>> Brainstorm AI est une application médicale visant à améliorer la détection, la localisation des tumeurs sur les images médicales des patients grâce au Deep-learning
            , à un modèle convolutionnel évolué (CNN) pour la classification/localisation des tumeurs et à un modèle U-Net pour effectuer la segmentation des images (segmentation pixel 
            par pixel avec labellisation -> pas de tumeur/tumeur) qui fait preuve d'une grande précision. Cette application est exploitable par des professionnels de santé (application de bureau) 
            et vise à améliorer le diagnostic ainsi que le suivi des patients en réduisant les erreurs de diagnostic. L'objectif est d'offrir une solution simple et facilement déployable sur la
            majorité des systèmes d'exploitation (Windows, MacOs). Une première version de cette application s'occupe de classer par type de tumeurs, localiser les tumeurs cérébrales, puis segmenter 
            l'image pour une grande précision. De nouvelles versions seront bientôt étudiées.
        </p>
        <div class="gallery">
            <figure>
                <img src="image/brainstorm_result_tumor_2.png" alt="Développement en cours">
                <figcaption>Localisation d'un gliome d'environ 2 cm sur une image IRM avec l'application de bureau Brainstorm</figcaption>
            </figure>
        </div>
    </section>

    <section id="brainstorm" class="section">
        <h2>Présentation de Brainstorm</h2>
        <p>Découvrez l'évolution du projet Brainstorm en défilant et cliquant les liens ci-dessous</p>
        <div class="timeline">
           <!-- Dixième date -->
            <div class="timeline-item">
                <a href="#date10" class="timeline-link">
                    <span class="timeline-date">16 Mai 2025</span>
                    <p> Segmentation de l'image médicale avec le modèle U-Net développé pour le projet de recherche 
                        (cf: Mines de Saint-Etienne)
                    </p>
                </a>
            </div>
           <!-- Neuvième date -->
            <div class="timeline-item">
                <a href="#date9" class="timeline-link">
                    <span class="timeline-date">12 Mai 2025</span>
                    <p> Entraînement du modèle CNN pour la détection, classification et localisation de tumeurs mammaires</p>
                </a>
            </div>
            
           <!-- Huitième date -->
            <div class="timeline-item">
                <a href="#date8" class="timeline-link">
                    <span class="timeline-date">06 Mai 2025</span>
                    <p>Evaluation de la taille approximative d'une tumeur (Computer Vision OpenCV)</p>
                </a>
            </div>
            
           <!-- Septième date -->
            <div class="timeline-item">
                <a href="#date7" class="timeline-link">
                    <span class="timeline-date">29 Avril 2025</span>
                    <p>Amélioration de la précision de la localisation des petites tumeurs grâce à un entraînement effectué sur plus de 66,000 images!</p>
                </a>
            </div>
            
            <!-- Première date -->
            <div class="timeline-item">
                <a href="#date1" class="timeline-link">
                    <span class="timeline-date">12 Avril 2025</span>
                    <p>Application de bureau Brainstorm à usage professionnel</p>
                </a>
            </div>
            <div class="timeline-item">
                <a href="#date2" class="timeline-link">
                    <span class="timeline-date">19 Février 2025</span>
                    <p>Implémentation du seuillage auto pour la détection des tumeurs + amélioration du modèle de classification</p>
                </a>
            </div>
            <!-- Deuxième date -->
            <div class="timeline-item">
                <a href="#date3" class="timeline-link">
                    <span class="timeline-date">10 Février 2025</span>
                    <p>Implémentation de la localisation des tumeurs avec la méthode "activation mapping"</p>
                </a>
            </div>

            <!-- Troisième date -->
            <div class="timeline-item">
                <a href="#date4" class="timeline-link">
                    <span class="timeline-date">12 Décembre 2024</span>
                    <p>Création de la version bêta de l'application Brainstorm</p>
                </a>
            </div>
            <!-- Quatrième date -->
            <div class="timeline-item">
                <a href="#date5" class="timeline-link">
                    <span class="timeline-date">7 Décembre 2024</span>
                    <p>Elaboration d'un modèle capable de détecter la présence d'une tumeur et perfectionnement du
                        modèle</p>
                </a>
            </div>
            <!-- Sixième date -->
            <div class="timeline-item">
                <a href="#date6" class="timeline-link">
                    <span class="timeline-date">2 Novembre 2024</span>
                    <p>Elaboration d'un modèle capable de détecter une tumeur et de classifier par type de tumeurs</p>
                </a>
            </div>
         </div>

            <!-- Ajoutez d'autres éléments ici -->
         <div id="date10">
                 <h3>16 Mai 2025 : Segmentation de l'image médicale avec le modèle U-Net du Projet de recherche (cf Mines de Saint-Etienne)</h3>


                  <p>>>> L'objectif de cette segmentation de l'image patient est d'offrir une distinction claire entre la tumeur et le reste des tissus
                      grâce au modèle U-Net développé lors du projet de recherche effectué aux Mines de Saint-Etienne (à savoir l'étude de l'activité calcique
                      des neuronnes pour la caractérisation des maladies neurodégénératives). Ce modèle U-Net est strictement identique dans sa structure, 
                      avec 4 couches dans l'encodeur/décodeur (sans compteur le Bottleneck), et ce dernier est basé sur 1 million
                      de paramètre. L'idée est donc d'offrir une segmentation plus précise si le praticien le souhaite (la méthode d'Activation mapping, bien que précise et fiable, ne permet
                      pas de faire une segmentation pixel par pixel). Les performances sont très satisfaisantes avec une accuracy approximative de 95% et une loss de 0,157. Via l'application,
                      l'utilisateur doit seulement appuyer sur le bouton "Segmentation U-Net" pour afficher la prédiction du modèle U-Net.
                    
                  </p>

                  <div class="gallery">
                      <figure>
                          <img src="image/u_net_1.png" alt="Développement en cours">
                          <figcaption> Segmentation de l'image avec la distinction Tumeur(s)/Sans Tumeurs pixel par pixel</figcaption>
                      </figure>
                  </div>

             
                  <div class="gallery">
                      <figure>
                          <img src="image/perfs.png" alt="Développement en cours">
                          <figcaption> Performances globales du modèle U-Net</figcaption>
                      </figure>
                  </div>
         </div>


         <div id="date9">
                 <h3>12 Mai 2025 : Entraînement du modèle CNN pour la détection, classification et localisation de tumeurs mammaires</h3>


                  <p>>>> Il s'agit ici d'un nouvel entraînement basé sur le même modèle mais avec un dataset d'entraînement différent, en particulier, il comporte d'autres classes (sans tumeur, benigne, maligne).
                         Les performances sur les données de test sont globalement satisfaisantes, même si inférieures aux performances de la détection des tumeurs cérébrales. Des améliorations sont à faire
                         en particulier au niveau de l'entraînement ainsi que sur la qualité du dataset.
                    
                  </p>

                  <div class="gallery">
                      <figure>
                          <img src="image/breast_tumors.png" alt="Développement en cours">
                          <figcaption> Classification et localisation des tumeurs mammaires avec l'Application Brainstorm </figcaption>
                      </figure>
                  </div>
         </div>

         <div id="date8">
                 <h3>06 Mai 2025 : Evaluation de la taille approximative d'une tumeur (Computer Vision OpenCV)</h3>


                  <p>>>> Une nouvelle fonction a été implémentée dans l'application, à savoir celle permettant de connaître avec une bonne précision la taille de la
                    tumeur (10 à 15% de marge d'erreur en moyenne). Cette fonction utilise la banque de computer vision OpenCV afin de récupérer le contour à la fois du
                    crâne et de la prédiction. En fonction de ces deux paramètres ainsi que le tour de tête du patient, on peut déterminer avec une bonne approximation
                    la taille de cette tumeur afin d'étayer le diagnostic médical. Des améliorations sont en cours, notamment pour essayer de réduire la marge d'erreur entre la 
                    taille calculée et la taille réelle de la tumeur.
                  </p>

                  <div class="gallery">
                      <figure>
                          <img src="image/tumor_brainstorm.png" alt="Développement en cours">
                          <figcaption> Approximation de la taille d'un gliome: 0.97 cm avec l'Application Brainstorm, 1.1 cm en réalité </figcaption>
                   
                      </figure>
                  </div>
            </div>




            
            <div id="date7">
               <h3>29 Avril 2025 : Amélioration de la précision de la localisation des petites tumeurs grâce à un entraînement effectué sur plus de 66,000 images</h3>


                <p>>>> Dans cette nouvelle étape du projet, l'idée était de tirer le meilleur potentiel de la génération de donnée afin de rendre le modèle encore plus robuste.
                  Afin d'obtenir ce dataset d'entraînement de plus de 66,000 images, l'objectif était de générer plus d'images, mais également de le faire avec des gaps plus
                  variés afin d'améliorer la robustesse dans la localisation précise des tumeurs, en particulier les plus petites et les plus inhabituelles par leur forme ou encore 
                   leur taille.
               </p>

               <div class="gallery">
                   <figure>
                       <img src="image/resultat6.png" alt="Développement en cours">
                       <figcaption> Détection d'une tumeur de 2 cm avec l'Application Brainstorm</figcaption>
                    
                   
                   </figure>
               </div>
        </div>
                
        <div id="date1">
            <h3>12 Avril 2025 : Application de bureau Brainstorm à usage professionnel</h3>


            <p>>>> L'application de bureau Brainstorm est enfin disponible sur Windows et MacOs! Cette première version adopte un design simpliste
                et intuitif, avec la possibilité de choisir le modèle d'IA : l'application proposera à l'avenir d'autres modèles de détection pour
                d'autres types de tumeurs afin d'élargir les utilisations. L'application est disponible en version V1.0 (pour obtenir des renseignements sur son fonctionnement,
                veuillez me contacter par mail qui se trouve dans l'espace "Contact";)
            </p>

            <div class="gallery">
                <figure>
                    <img src="image/app_bureau.png" alt="Développement en cours">
                    <figcaption> Application de bureau Brainstorm</figcaption>
                    
                   
                </figure>
            </div>
            
            <p> 
                >>> L'interface comprend un choix de modèle d'IA, un accès au répertoire local pour charger une image, un curseur pour affiner la précision
                    du seuillage automatique des prédictions "Grad-Cam", un bouton pour rafraîchir la page, et bien évidemment, l'affichage du type de tumeur
                    avec l'indice de confiance de la prédiction !
            </p>



        
        </div>
        <div id="date2">
            <h3>19 Février 2025 : Implémentation du seuillage auto et manuel pour la détection des tumeurs + amélioration du modèle de classification</h3>


            <p>>>> Le seuillage automatique est une nouvelle fonctionnalité offerte par l'application. Elle permet de cibler directement la zone d'activation
             qui participe à la prise de décision du modèle. L'application intègre désormais la classification des tumeurs avec un modèle CNN qui possède plus de filtres 
             et donc plus de paramètres. Les performances sont globalement satisfaisantes et en améliorations avec une Accuracy de 97,8 % et une Loss de 0.10. Le modèle est globalement
             plus robuste, notamment grâce à l'augmentation des données du dataset d'entraînement.

            </p>

            <div class="gallery">
                <figure>
                    <img src="image/brainstorm_result_tumor_1.png" alt="Développement en cours">
                    <figcaption> Résultats de la localisation d'une tumeur cérébrale de type méningiome </figcaption>
                    
                    <img src="image/brainstorm_result_3.png" alt="Développement en cours">
                    <figcaption> Résultats de la localisation d'une tumeur cérébrale de type gliome </figcaption>

                    <img src="image/seuil_sanstumeur.png" alt="Développement en cours">
                    <figcaption> Résultats de la localisation sans tumeur </figcaption>
                </figure>
            </div>

 

            <p> 
            </p>



        </div>
        <div id="date3">
            <h3>10 Février 2025 : Activation Mapping</h3>


            <p>>>> Implémentation de la méthode "activation mapping"
                pour cibler et localiser les zones qui contribuent le plus à la prise
                de décision du modèle. Voici ci-dessous un exemple du fonctionnement
                sur deux images médicales de cette méthode de détection

            </p>

            <div class="gallery">
                <figure>
                    <img src="image/1.png" alt="Développement en cours">
                    <figcaption>Résultats de la localisation de la tumeur cérébrale (gliome) sur deux exemples (données
                        de tests)</figcaption>
                </figure>
            </div>

            <div class="gallery">
                <video controls>
                    <source src="image/localisation.mp4" type="video/mp4">
                    Votre navigateur ne supporte pas la lecture de vidéos.
                </video>
            </div>

            <p> L'intérêt d'utiliser cette méthode réside dans la capacité à obtenir
                la localisation de la tumeur avec une grande précision via l'application
                d'un seuillage et d'un filtrage. Néanmoins, comme on peut le constater,
                le filtrage n'est pas encore optimal (notamment au niveau du crâne).
                Cela fera l'objet de la prochaine amélioration.
            </p>

            <div class="gallery" style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="image/tumeur.png" alt="Développement en cours">
                    <img src="image/tumeur1.png" alt="Développement en cours">
                    <figcaption>Prédiction de cancer chez le patient avec localisation de la tumeur sur l'application
                        Brainstorm</figcaption>

                </figure>
            </div>

        </div>
        <div id="date4">
            <h3>12 Décembre 2024 : Création de la version bêta de l'application Brainstorm</h3>


            <p>>>> Création d'une première version de l'interface utilisateur avec le modèle
                CNN développé précédemment. Cette intégration du modèle est modulaire, permettant
                ainsi de continuer son amélioration en parallèle du développement de l'application
                et des fonctionalités comme la localisation de la tumeur (cette fonctionnalité sera intégrée
                prochainement).

            </p>

            <div class="gallery">
                <video controls>
                    <source src="image/brainstorm.mp4" type="video/mp4">
                    Votre navigateur ne supporte pas la lecture de vidéos.
                </video>

            </div>
            <p> Dans cette première version de l'application, l'objectif est
                d'offrir une interface simple d'utilisation, avec un lien pour
                charger l'image depuis un répertoire local. Le modèle CNN implémenté
                dans l'application se charge ainsi à donner une évaluation de la prédiction,
                et confirme si le patient possède une tumeur ou non.

            </p>

        </div>
        <div id="date5">
            <h3>7 Novembre 2024 : Elaboration d'un modèle capable de détecter la présence d'une tumeur et
                perfectionnement du modèle</h3>


            <p>>>> L'application repose sur un modèle CNN conçu pour détecter et avertir le
                praticien de l'éventuelle présence d'une tumeur chez un patient. Le modèle est entraîné avec
                plus de 1780 images, et validé avec 1190 images médicales sur 20 epochs. Les performances sont
                globalement satisfaisantes, avec une accuracy de 99% et une loss de 0.03 ~ 0.04 sur les données de
                validation,
                sans overfitting!

            </p>

            <div class="gallery" style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="image/resultats.png" alt="Développement en cours">
                    <figcaption>Résultats du modèle CNN développé</figcaption>

                </figure>
            </div>
            <p>

            </p>
            <div class="gallery" style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="image/courbe_precision.png" alt="Développement en cours">
                    <img src="image/courbe_loss.png" alt="Développement en cours">
                    <figcaption>Courbes de l'Accuracy et de la Loss</figcaption>

                </figure>
            </div>

        </div>
        <div id="date6">
            <h3>2 Novembre 2024 : Elaboration d'un modèle capable de détecter une tumeur et de classifier par type de
                tumeurs</h3>


            <p>>>> L'application repose sur un modèle CNN spécialement conçu pour détecter des tumeurs et classer une
                image médicale
                d'un patient selon le type de tumeurs (méningiome, gliome, etc...). Le praticien peut donc déterminer
                avec une plus grande précision de l'éventuelle présence d'une tumeur chez un patient.
                Le modèle est entraîné avec plus de 1780 images, et validé avec 1190 images médicales sur 30 epochs. Les
                performances sont
                globalement satisfaisantes, avec une accuracy de 91% et une loss de ~ 0.27 sur les données de
                validation, sans overfitting.

            </p>
            <div class="gallery">
                <figure>
                    <img src="image/results.png" alt="Développement en cours">
                    <figcaption>Résultats du modèle CNN développé</figcaption>
                </figure>
            </div>

            <div class="gallery" style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="image/accuracy.png" alt="Développement en cours">
                    <img src="image/loss.png" alt="Développement en cours">
                    <figcaption>Courbes de l'Accuracy et de la Loss</figcaption>

                </figure>
            </div>


            <p> L'intérêt de ce modèle réside dans l'utilisation de la fonction "prédiction" pour évaluer si une image
                médicale
                comporte une tumeur de type gliome, méningiome, etc ou si le patient n'a aucune tumeur. Voici ci-dessous
                deux exemples de prédiction basés sur le modèle

            </p>

            <div class="gallery" style="display: flex; justify-content: space-around;">
                <figure>
                    <img src="image/meningiome.png" alt="Développement en cours">
                    <img src="image/gliome.png" alt="Développement en cours">
                    <figcaption>Prédiction du type de cancer pour deux images tests</figcaption>

                </figure>
            </div>

        </div>


    </section>

    <section id="NeuronDetect" class="section">
        <h2>Présentation de NeuronDetect</h2>
        <p>Découvrez l'évolution du projet NeuronDetect en cliquant sur les liens</p>
        <div class="timeline">
            <!-- Première date -->
            <div class="timeline-item">
                <a href="#date100" class="timeline-link">
                    <span class="timeline-date">20 Mars 2025</span>
                    <p> Réalisation d'un U-Net permettant la détection automatique de l'activité calcique des neurones</p>
                </a>
            </div>
        </div>
        <div id="date100">
            <h3>20 Mars 2025 : Réalisation d'un U-Net permettant la détection automatique de l'activité calcique des neurones</h3>


            <p>>>> Dans ce projet, nous cherchons à détecter à l'aide d'un modèle convolutionnel de type U-Net les activités calciques
                de neurones situés dans la moelle épinière afin d'automatiser cette détection. Ce modèle U-Net est plus évolué que le CNN 
                utilisé pour le projet Brainstorm, puisqu'il comporte trois parties: un encodeur, un bottleneck ainsi qu'un décodeur. 
                L'objectif de ce projet est donc de récupérer les prédictions du modèle et d'y effectuer un post-traitement pour repérer ces neurones
                en les entourant.

            </p>

            <div class="gallery">
                <figure>
                    
                    <img src="image/NeuronDetect.png" alt="Développement en cours">
                    <figcaption> Résultats Post-traitement de la détection de l'activité calcique des neurones </figcaption>
                     
                </figure>
            </div>

            <p> Une étape cruciale du projet consistait à effectuer un "labeling" de qualité pour nos datasets d'entrée. L'objectif consiste, 
                dans un premier temps, à réduire les différents bruits électroniques liés au microscope (ils se remarquent avec l'apparition de 
                points lumineux, assimilables à des neurones). Un prétraitement est donc nécessaire pour obtenir des labels de qualité pour l'entraînement
                du modèle (on cherche à fabriquer des masques pour les labels). Pour cela, des filtres spécifiques ont été utilisés, dont un filtre gaussian
                pour appliquer un flou et réduire la taille ainsi que l'intensité des (petits) points lumineux. Une autre technique consistait à appliquer
                un filtre bilatéral pour également appliquer un flou sur des grandes aires, tout en améliorant les contours délimitant deux espaces (dans notre 
                cas, les neurones et le fond de l'image). Enfin, une dernière étape consiste à appliquer un seuil pour "binariser" le masque en deux labels distincts:
                "0" pour le fond de l'image et "1" pour les neurones). On obtient au final ce type de label-masque!
                 
            </p>
            <div class="gallery">
                <figure>
                    
                    <img src="image/example1.png" alt="Développement en cours">
                    <figcaption> Exemple d'image d'un dataset d'entraînement  </figcaption>
                     
                </figure>         
            
                <figure>
                    
                    <img src="image/example2.png" alt="Développement en cours">
                    <figcaption> Masque associé à l'image précédente </figcaption>
                     
                </figure>
            </div>



        </div>
    </section>

    <section id="quisuisje" class="section">
        <h2>Fondateur</h2>
        <p>Je suis Grégory BERTRAND, fondateur de Brainstorm AI et développeur de l'application Brainstorm,
            étudiant ingénieur en 3ème année aux Mines de Saint-Etienne et enfin 
            stagiaire - Ingénieur Système en Imagerie Médicale chez Thales. Passionné
            par les nouvelles technologies depuis mon adolescence, je m'intéresse depuis
            maintenant plus de 3 ans à l'application du Machine Learning dans la vie
            quotidienne, et en particulier dans le domaine du diagnostic médical.
        </p>
    </section>

    <section id="contact" class="section">
        <h2>Contact</h2>
        <p>Si l'application Brainstorm vous intéresse, ou que vous avez simplement des questions concernant l'application,
            vous pouvez me contacter à l'adresse mail suivante : <a
                href="mailto:gregory.bertrand@etu.emse.fr">gregory.bertrand@etu.emse.fr</a></p>
    </section>

    <footer>
        <p>&copy; 2025 Brainstorm AI. Tous droits réservés.</p>
        <div class="counter-container">
        
    </div>
    </footer>
    
    <script>
    window.onscroll = function() {
        var button = document.getElementById("backToTop");
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            button.style.display = "block";
        } else {
            button.style.display = "none";
        }
    };

    function scrollToTop() {
        window.scrollTo({ top: 0, behavior: 'smooth' });
    }
</script>
<script>
    function openLinkedIn() {
        window.open("https://www.linkedin.com/in/bertrand-gr%C3%A9gory/", "_blank");
    }
</script>
<script>
    function GitHub() {
        window.open("https://github.com/GregoryEmbedded/brainstorm", "_blank");
    }
</script>

   
  
</body>

</html>
